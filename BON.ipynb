{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValerieGrimault/Coherence_des_donnees/blob/master/BON.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aX1dRHHVUUs",
        "outputId": "3c954409-b88b-417a-ecca-57dc105a01b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: autokeras==1.0.17rc1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 1)) (1.0.17rc1)\n",
            "Requirement already satisfied: keras-nightly==2.8.0.dev2021101807 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 2)) (2.8.0.dev2021101807)\n",
            "Requirement already satisfied: keras-tuner==1.1.0rc0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (1.1.0rc0)\n",
            "Requirement already satisfied: numpy==1.21.2 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 4)) (1.21.2)\n",
            "Requirement already satisfied: pandas==1.3.4 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 5)) (1.3.4)\n",
            "Requirement already satisfied: scikit-learn==1.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 6)) (1.0)\n",
            "Requirement already satisfied: scipy==1.7.1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 7)) (1.7.1)\n",
            "Requirement already satisfied: tf-nightly==2.8.0.dev20211016 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (2.8.0.dev20211016)\n",
            "Requirement already satisfied: matplotlib==3.4.3 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 9)) (3.4.3)\n",
            "Requirement already satisfied: seaborn==0.11.2 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 10)) (0.11.2)\n",
            "Requirement already satisfied: pydotplus==2.0.2 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 11)) (2.0.2)\n",
            "Requirement already satisfied: graphviz==0.17 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 12)) (0.17)\n",
            "Requirement already satisfied: packaging in c:\\users\\valha\\anaconda3\\lib\\site-packages (from autokeras==1.0.17rc1->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 1)) (21.0)\n",
            "Requirement already satisfied: requests in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (2.26.0)\n",
            "Requirement already satisfied: ipython in c:\\users\\valha\\anaconda3\\lib\\site-packages (from keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (7.29.0)\n",
            "Requirement already satisfied: tensorboard in c:\\users\\valha\\anaconda3\\lib\\site-packages (from keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (2.7.0)\n",
            "Requirement already satisfied: kt-legacy in c:\\users\\valha\\anaconda3\\lib\\site-packages (from keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (1.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from pandas==1.3.4->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from pandas==1.3.4->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 5)) (2021.3)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from scikit-learn==1.0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from scikit-learn==1.0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 6)) (2.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (12.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (3.19.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (2.0)\n",
            "Requirement already satisfied: tb-nightly~=2.7.0.a in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (2.7.0a20211013)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (1.43.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (1.16.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (0.23.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (1.12.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (0.37.0)\n",
            "Requirement already satisfied: tf-estimator-nightly~=2.8.0.dev in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (3.10.0.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from matplotlib==3.4.3->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from matplotlib==3.4.3->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 9)) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from matplotlib==3.4.3->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from matplotlib==3.4.3->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 9)) (0.10.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (2.0.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (58.0.4)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (2.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (1.8.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from requests->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (3.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from requests->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (1.26.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from requests->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from requests->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.7.0.a->tf-nightly==2.8.0.dev20211016->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 8)) (3.1.1)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (0.18.0)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\valha\\anaconda3\\lib\\site-packages (from ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (0.4.4)\n",
            "Requirement already satisfied: pygments in c:\\users\\valha\\anaconda3\\lib\\site-packages (from ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (2.10.0)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\valha\\anaconda3\\lib\\site-packages (from ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (3.0.20)\n",
            "Requirement already satisfied: decorator in c:\\users\\valha\\anaconda3\\lib\\site-packages (from ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (5.1.0)\n",
            "Requirement already satisfied: backcall in c:\\users\\valha\\anaconda3\\lib\\site-packages (from ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (5.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\valha\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (0.8.2)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\valha\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner==1.1.0rc0->-r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt (line 3)) (0.2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r https://raw.githubusercontent.com/datamllab/automl-in-action-notebooks/master/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moeJ8hRq-NYA",
        "outputId": "ff61d016-bd1a-49af-b99a-4431f6af9446"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting autokeras\n",
            "  Using cached autokeras-1.0.16.post1-py3-none-any.whl (166 kB)\n",
            "Requirement already satisfied: packaging in c:\\users\\valha\\anaconda4\\lib\\site-packages (from autokeras) (21.0)\n",
            "Requirement already satisfied: pandas in c:\\users\\valha\\anaconda4\\lib\\site-packages (from autokeras) (1.3.4)\n",
            "Collecting tensorflow<2.6,>=2.3.0\n",
            "  Using cached tensorflow-2.5.2-cp39-cp39-win_amd64.whl (422.7 MB)\n",
            "Collecting keras-tuner<1.1,>=1.0.2\n",
            "  Using cached keras_tuner-1.0.4-py3-none-any.whl (97 kB)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\valha\\anaconda4\\lib\\site-packages (from autokeras) (0.24.2)\n",
            "Requirement already satisfied: ipython in c:\\users\\valha\\anaconda4\\lib\\site-packages (from keras-tuner<1.1,>=1.0.2->autokeras) (7.29.0)\n",
            "Requirement already satisfied: requests in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from keras-tuner<1.1,>=1.0.2->autokeras) (2.26.0)\n",
            "Collecting kt-legacy\n",
            "  Using cached kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\valha\\anaconda4\\lib\\site-packages (from keras-tuner<1.1,>=1.0.2->autokeras) (1.20.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\valha\\anaconda4\\lib\\site-packages (from keras-tuner<1.1,>=1.0.2->autokeras) (1.7.1)\n",
            "Collecting tensorboard\n",
            "  Using cached tensorboard-2.7.0-py3-none-any.whl (5.8 MB)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Using cached grpcio-1.34.1-cp39-cp39-win_amd64.whl (2.9 MB)\n",
            "Collecting flatbuffers~=1.12.0\n",
            "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting google-pasta~=0.2\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting protobuf>=3.9.2\n",
            "  Using cached protobuf-3.19.1-cp39-cp39-win_amd64.whl (895 kB)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from tensorflow<2.6,>=2.3.0->autokeras) (1.12.1)\n",
            "Collecting opt-einsum~=3.3.0\n",
            "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "Collecting six~=1.15.0\n",
            "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting gast==0.4.0\n",
            "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting astunparse~=1.6.3\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting keras-preprocessing~=1.1.2\n",
            "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "Collecting absl-py~=0.10\n",
            "  Using cached absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "Collecting h5py~=3.1.0\n",
            "  Using cached h5py-3.1.0-cp39-cp39-win_amd64.whl (2.7 MB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0\n",
            "  Using cached tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "Collecting numpy\n",
            "  Using cached numpy-1.19.5-cp39-cp39-win_amd64.whl (13.3 MB)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from tensorflow<2.6,>=2.3.0->autokeras) (0.37.0)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Using cached keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from tensorboard->keras-tuner<1.1,>=1.0.2->autokeras) (58.0.4)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Using cached tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard->keras-tuner<1.1,>=1.0.2->autokeras) (2.0.2)\n",
            "Collecting markdown>=2.6.8\n",
            "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Using cached google_auth-2.3.3-py2.py3-none-any.whl (155 kB)\n",
            "Collecting cachetools<5.0,>=2.0.0\n",
            "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Using cached requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from markdown>=2.6.8->tensorboard->keras-tuner<1.1,>=1.0.2->autokeras) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner<1.1,>=1.0.2->autokeras) (3.6.0)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from requests->keras-tuner<1.1,>=1.0.2->autokeras) (3.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from requests->keras-tuner<1.1,>=1.0.2->autokeras) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from requests->keras-tuner<1.1,>=1.0.2->autokeras) (2.0.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from requests->keras-tuner<1.1,>=1.0.2->autokeras) (1.26.7)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Using cached oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from ipython->keras-tuner<1.1,>=1.0.2->autokeras) (3.0.20)\n",
            "Requirement already satisfied: colorama in c:\\users\\valha\\appdata\\roaming\\python\\python39\\site-packages (from ipython->keras-tuner<1.1,>=1.0.2->autokeras) (0.4.4)\n",
            "Requirement already satisfied: traitlets>=4.2 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from ipython->keras-tuner<1.1,>=1.0.2->autokeras) (5.1.0)\n",
            "Requirement already satisfied: matplotlib-inline in c:\\users\\valha\\anaconda4\\lib\\site-packages (from ipython->keras-tuner<1.1,>=1.0.2->autokeras) (0.1.2)\n",
            "Requirement already satisfied: backcall in c:\\users\\valha\\anaconda4\\lib\\site-packages (from ipython->keras-tuner<1.1,>=1.0.2->autokeras) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from ipython->keras-tuner<1.1,>=1.0.2->autokeras) (0.18.0)\n",
            "Requirement already satisfied: pickleshare in c:\\users\\valha\\anaconda4\\lib\\site-packages (from ipython->keras-tuner<1.1,>=1.0.2->autokeras) (0.7.5)\n",
            "Requirement already satisfied: pygments in c:\\users\\valha\\anaconda4\\lib\\site-packages (from ipython->keras-tuner<1.1,>=1.0.2->autokeras) (2.10.0)\n",
            "Requirement already satisfied: decorator in c:\\users\\valha\\anaconda4\\lib\\site-packages (from ipython->keras-tuner<1.1,>=1.0.2->autokeras) (5.1.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from jedi>=0.16->ipython->keras-tuner<1.1,>=1.0.2->autokeras) (0.8.2)\n",
            "Requirement already satisfied: wcwidth in c:\\users\\valha\\anaconda4\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner<1.1,>=1.0.2->autokeras) (0.2.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from packaging->autokeras) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from pandas->autokeras) (2021.3)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from scikit-learn->autokeras) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\valha\\anaconda4\\lib\\site-packages (from scikit-learn->autokeras) (2.2.0)\n",
            "Installing collected packages: pyasn1, six, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, markdown, grpcio, google-auth-oauthlib, absl-py, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, kt-legacy, keras-preprocessing, keras-nightly, h5py, google-pasta, gast, flatbuffers, astunparse, tensorflow, keras-tuner, autokeras\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.20.3\n",
            "    Uninstalling numpy-1.20.3:\n",
            "      Successfully uninstalled numpy-1.20.3\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.10.0.2\n",
            "    Uninstalling typing-extensions-3.10.0.2:\n",
            "      Successfully uninstalled typing-extensions-3.10.0.2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.2.1\n",
            "    Uninstalling h5py-3.2.1:\n",
            "      Successfully uninstalled h5py-3.2.1\n",
            "Successfully installed absl-py-0.15.0 astunparse-1.6.3 autokeras-1.0.16.post1 cachetools-4.2.4 flatbuffers-1.12 gast-0.4.0 google-auth-2.3.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 keras-tuner-1.0.4 kt-legacy-1.0.4 markdown-3.3.6 numpy-1.19.5 oauthlib-3.1.1 opt-einsum-3.3.0 protobuf-3.19.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.8 six-1.15.0 tensorboard-2.7.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.5.2 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
            "conda-repo-cli 1.0.4 requires pathlib, which is not installed.\n",
            "cookiecutter 1.7.2 requires Jinja2<3.0.0, but you have jinja2 3.0.2 which is incompatible.\n",
            "cookiecutter 1.7.2 requires MarkupSafe<2.0.0, but you have markupsafe 2.0.1 which is incompatible.\n",
            "bokeh 2.4.1 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "pip install autokeras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd9PcyJF-NYC"
      },
      "source": [
        "## Titanic data downloaded with csv files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sSYqvMQ-NYD"
      },
      "source": [
        "### Download training and testing csv files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TfEwnFXWnmS"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
        "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
        " \n",
        "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewJYtKie-NYE"
      },
      "source": [
        "### Run `StructuredDataClassifier` API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i31igxa3-NYE",
        "outputId": "25985074-9852-47fa-dafc-c89255caa09f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project .\\structured_data_classifier\\oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from .\\structured_data_classifier\\tuner0.json\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'structured_data_block_2/normalize'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13968/474595846.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Feed the structured data classifier with training data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m clf.fit(\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m# The path to the train.csv file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtrain_file_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\tasks\\structured_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m                 \u001b[0mvalidation\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mif\u001b[0m \u001b[0mapplicable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \"\"\"\n\u001b[1;32m--> 326\u001b[1;33m         history = super().fit(\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\tasks\\structured_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_in_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         history = super().fit(\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m             )\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         history = self.tuner.search(\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\engine\\tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         super().search(\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         )\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuner_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTOPPED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[1;31m# Oracle triggered exit.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36mcreate_trial\u001b[1;34m(self, tuner_id)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"status\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"values\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"values\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\tuners\\greedy.py\u001b[0m in \u001b[0;36mpopulate_space\u001b[1;34m(self, trial_id)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_collisions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mhp_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_hps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_hp_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m             \u001b[1;31m# Reached max collisions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\tuners\\greedy.py\u001b[0m in \u001b[0;36m_generate_hp_values\u001b[1;34m(self, hp_names)\u001b[0m\n\u001b[0;32m    186\u001b[0m                     \u001b[1;31m# if was active and not selected, do nothing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mbest_hps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_active\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhp_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                         \u001b[0mhps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_hps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m                         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                     \u001b[1;31m# if was not active or selected, sample.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'structured_data_block_2/normalize'"
          ]
        }
      ],
      "source": [
        "# Initialize the structured data classifier.\n",
        "clf = ak.StructuredDataClassifier(max_trials=1) # Try 10 different pipelines.\n",
        "\n",
        "# Feed the structured data classifier with training data.\n",
        "clf.fit(\n",
        "    # The path to the train.csv file.\n",
        "    train_file_path,\n",
        "    # The name of the label column.\n",
        "    'survived',\n",
        "    verbose=2,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meGPxUAAXEZL",
        "outputId": "6bd940e8-1e20-4f6c-defc-ef42c4253fb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project .\\structured_data_classifier\\oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from .\\structured_data_classifier\\tuner0.json\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'structured_data_block_2/normalize'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13968/3060018874.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m clf.fit(\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mtrain_file_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;34m'survived'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\tasks\\structured_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m                 \u001b[0mvalidation\u001b[0m \u001b[0mloss\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvalidation\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mif\u001b[0m \u001b[0mapplicable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \"\"\"\n\u001b[1;32m--> 326\u001b[1;33m         history = super().fit(\n\u001b[0m\u001b[0;32m    327\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\tasks\\structured_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_in_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         history = super().fit(\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\auto_model.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m             )\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         history = self.tuner.search(\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\engine\\tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         super().search(\n\u001b[0m\u001b[0;32m    188\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnew_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         )\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_search_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m             \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuner_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTOPPED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[1;31m# Oracle triggered exit.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\keras_tuner\\engine\\oracle.py\u001b[0m in \u001b[0;36mcreate_trial\u001b[1;34m(self, tuner_id)\u001b[0m\n\u001b[0;32m    188\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpopulate_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"status\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"values\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"values\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresponse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\tuners\\greedy.py\u001b[0m in \u001b[0;36mpopulate_space\u001b[1;34m(self, trial_id)\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_max_collisions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mhp_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_hps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_hp_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m             \u001b[1;31m# Reached max collisions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\autokeras\\tuners\\greedy.py\u001b[0m in \u001b[0;36m_generate_hp_values\u001b[1;34m(self, hp_names)\u001b[0m\n\u001b[0;32m    186\u001b[0m                     \u001b[1;31m# if was active and not selected, do nothing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mbest_hps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_active\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhp_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                         \u001b[0mhps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_hps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m                         \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m                     \u001b[1;31m# if was not active or selected, sample.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'structured_data_block_2/normalize'"
          ]
        }
      ],
      "source": [
        "import autokeras as ak\n",
        "clf = ak.StructuredDataClassifier(\n",
        "    column_names=[\n",
        "        'sex',\n",
        "        'age',\n",
        "        'n_siblings_spouses',\n",
        "        'parch',\n",
        "        'fare',\n",
        "        'class',\n",
        "        'deck',\n",
        "        'embark_town',\n",
        "        'alone'],\n",
        "    column_types={'sex': 'categorical',\n",
        "                  'fare': 'numerical'},\n",
        "    max_trials=2,\n",
        ")\n",
        "\n",
        "clf.fit(\n",
        "    train_file_path,\n",
        "    'survived',\n",
        "    verbose=2,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I59cfzoC-NYE"
      },
      "source": [
        "### Predict with the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c917f2uf-NYF",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "predicted_y = clf.predict(test_file_path)\n",
        "print(predicted_y[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRuytpW3-NYF"
      },
      "source": [
        "### Evaluate the best pipeline with the testing csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsdeaKpA-NYG"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = clf.evaluate(test_file_path, 'survived', verbose=0)\n",
        "print('Test accuracy: ', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jZrlHcWosL1"
      },
      "outputs": [],
      "source": [
        "best_model = clf.export_model()\n",
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cnj5WFbqosL1"
      },
      "outputs": [],
      "source": [
        " tf.keras.utils.plot_model(best_model, show_shapes=True, expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF_jI2QNosL1"
      },
      "outputs": [],
      "source": [
        "test_file_path = test_file_path.astype('string')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0JN0FCrosL2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "test = pd.read_csv('C:/Users/valha/Documents/Classeur1.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RBnLLYdBosL2"
      },
      "outputs": [],
      "source": [
        "predicted_y = best_model.predict(test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pR0-f6josL2"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow==2.5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skNzAUlXosL2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('C:/Users/valha/Downloads/titanic.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8oLCCXjosL2"
      },
      "outputs": [],
      "source": [
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Bpq4zr-osL3"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_adhqidEosL3"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE0sa1HOosL3"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns = ['Survived'],axis=1)\n",
        "y = df['Survived']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L5iHPbbouuN",
        "outputId": "4618b77c-8af9-4f6f-aecc-fdedc5a8e938"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('drive/My Drive/BNA/BNA 2022-MEAE-Données brutes.xlsx') "
      ],
      "metadata": {
        "id": "tu3efa8oo8hD"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "MgNXSSE6pRok",
        "outputId": "112df842-f238-47bd-c05f-86c1271e2e93"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Ministere Q1.Maitrise_ENT  \\\n",
              "0  Ministère de l'Europe et des Affaires Etrangères     Plutôt bien   \n",
              "1  Ministère de l'Europe et des Affaires Etrangères        Très mal   \n",
              "2  Ministère de l'Europe et des Affaires Etrangères     Plutôt bien   \n",
              "3  Ministère de l'Europe et des Affaires Etrangères       Très bien   \n",
              "4  Ministère de l'Europe et des Affaires Etrangères     Plutôt bien   \n",
              "\n",
              "                             Q2.Sedentaire_ou_nomade  \\\n",
              "0  Majoritairement sédentaire (lieu de travail fi...   \n",
              "1  Majoritairement nomade (déplacements fréquents...   \n",
              "2  Majoritairement sédentaire (lieu de travail fi...   \n",
              "3  Majoritairement sédentaire (lieu de travail fi...   \n",
              "4  Majoritairement nomade (déplacements fréquents...   \n",
              "\n",
              "                          Q3.Frequence_teletravail  \\\n",
              "0  Très régulièrement (1 jour par semaine ou plus)   \n",
              "1              Régulièrement (1 à 3 fois par mois)   \n",
              "2                                           Jamais   \n",
              "3                Rarement (de 1 à 11 jours par an)   \n",
              "4  Très régulièrement (1 jour par semaine ou plus)   \n",
              "\n",
              "                          Q4.Equipements_possedes Q5.equipement_prive_vs_pro  \\\n",
              "0                             Ordinateur portable                 Moins bien   \n",
              "1  Ordinateur fixe;Ordinateur portable;Smartphone                 Moins bien   \n",
              "2                                 Ordinateur fixe                 Moins bien   \n",
              "3                  Ordinateur portable;Smartphone    Ni mieux, ni moins bien   \n",
              "4                  Ordinateur portable;Smartphone    Ni mieux, ni moins bien   \n",
              "\n",
              "        Q6.Utilisation_equipement_prive  \\\n",
              "0  Oui, parce qu'il est plus performant   \n",
              "1  Oui, parce qu'il est plus performant   \n",
              "2            Non, je ne le souhaite pas   \n",
              "3            Non, je ne le souhaite pas   \n",
              "4            Non, je ne le souhaite pas   \n",
              "\n",
              "                     Q7.amelioration_Ordinateur_Fixe  \\\n",
              "0                                                NaN   \n",
              "1  L’absence de bugs (dysfonctionnement du logici...   \n",
              "2                               L’espace de stockage   \n",
              "3                                                NaN   \n",
              "4                                                NaN   \n",
              "\n",
              "                 Q8.amelioration_Ordinateur_Portable Q9.amelioration_Tablette  \\\n",
              "0                               La taille de l’écran                      NaN   \n",
              "1  La possibilité de travailler simultanément sur...                      NaN   \n",
              "2                                                NaN                      NaN   \n",
              "3          Les ports disponibles (USB, HDMI, VGA...)                      NaN   \n",
              "4     L’encombrement (taille, poids de l’équipement)                      NaN   \n",
              "\n",
              "   ... QS1_MEAE_genre QS2_MEAE_outils_de_travail_a_distance  \\\n",
              "0  ...       Un homme                                Itinéo   \n",
              "1  ...      Une femme                        Itinéo;Smarteo   \n",
              "2  ...       Un homme                                 Aucun   \n",
              "3  ...      Une femme                        Itinéo;Smarteo   \n",
              "4  ...       Un homme                        Itinéo;Smarteo   \n",
              "\n",
              "                   QS3_MEAE_niveau_acces_equipements  \\\n",
              "0  Utilisateur (sans pouvoir installer des applic...   \n",
              "1  Utilisateur (sans pouvoir installer des applic...   \n",
              "2  Utilisateur (sans pouvoir installer des applic...   \n",
              "3  Utilisateur (sans pouvoir installer des applic...   \n",
              "4  Utilisateur (sans pouvoir installer des applic...   \n",
              "\n",
              "                               QS4_MEAE_applications  \\\n",
              "0  Word;Excel;Outlook;Diplomatie;Diplonet;Viséo;F...   \n",
              "1  Excel;Word;Diplonet;Portail Elise;Powerpoint;V...   \n",
              "2  RMV-France Visas;Portail Elise;Sagha;Colimatic...   \n",
              "3  Word;Diplonet;Excel;Portail Elise;Powerpoint;V...   \n",
              "4  Word;Diplonet;Sagha;Excel;Portail Elise;Powerp...   \n",
              "\n",
              "                            QS5_MEAE_informations QS6_MEAE_informations_bis  \\\n",
              "0       Toujours accessibles et rapides à trouver                En général   \n",
              "1       Toujours accessibles et rapides à trouver                En général   \n",
              "2  Toujours accessibles mais difficiles à trouver                En général   \n",
              "3  Toujours accessibles mais difficiles à trouver                En général   \n",
              "4                          Je dois les rechercher                       Non   \n",
              "\n",
              "                       QS7_MEAE_interactions  \\\n",
              "0  Individuellement avec plusieurs personnes   \n",
              "1                    Au sein de votre équipe   \n",
              "2                      Avec d'autres équipes   \n",
              "3                      Avec d'autres équipes   \n",
              "4                      Avec d'autres équipes   \n",
              "\n",
              "                                  QS8_MEAE_activites           DATE_ENREG  \\\n",
              "0                                         Messagerie  14/03/2022 12:43:00   \n",
              "1                             Discussion instantanée  14/03/2022 14:11:52   \n",
              "2                                         Messagerie  14/03/2022 14:12:45   \n",
              "3  Messagerie;Discussion instantanée;Echanges ora...  14/03/2022 14:13:51   \n",
              "4  Echanges oraux (présentiel ou visioconférence)...  14/03/2022 14:14:35   \n",
              "\n",
              "  PROGRESSION  \n",
              "0     Terminé  \n",
              "1     Terminé  \n",
              "2     Terminé  \n",
              "3     Terminé  \n",
              "4     Terminé  \n",
              "\n",
              "[5 rows x 59 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a214db85-baa2-412a-af4a-159281a32ab7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ministere</th>\n",
              "      <th>Q1.Maitrise_ENT</th>\n",
              "      <th>Q2.Sedentaire_ou_nomade</th>\n",
              "      <th>Q3.Frequence_teletravail</th>\n",
              "      <th>Q4.Equipements_possedes</th>\n",
              "      <th>Q5.equipement_prive_vs_pro</th>\n",
              "      <th>Q6.Utilisation_equipement_prive</th>\n",
              "      <th>Q7.amelioration_Ordinateur_Fixe</th>\n",
              "      <th>Q8.amelioration_Ordinateur_Portable</th>\n",
              "      <th>Q9.amelioration_Tablette</th>\n",
              "      <th>...</th>\n",
              "      <th>QS1_MEAE_genre</th>\n",
              "      <th>QS2_MEAE_outils_de_travail_a_distance</th>\n",
              "      <th>QS3_MEAE_niveau_acces_equipements</th>\n",
              "      <th>QS4_MEAE_applications</th>\n",
              "      <th>QS5_MEAE_informations</th>\n",
              "      <th>QS6_MEAE_informations_bis</th>\n",
              "      <th>QS7_MEAE_interactions</th>\n",
              "      <th>QS8_MEAE_activites</th>\n",
              "      <th>DATE_ENREG</th>\n",
              "      <th>PROGRESSION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ministère de l'Europe et des Affaires Etrangères</td>\n",
              "      <td>Plutôt bien</td>\n",
              "      <td>Majoritairement sédentaire (lieu de travail fi...</td>\n",
              "      <td>Très régulièrement (1 jour par semaine ou plus)</td>\n",
              "      <td>Ordinateur portable</td>\n",
              "      <td>Moins bien</td>\n",
              "      <td>Oui, parce qu'il est plus performant</td>\n",
              "      <td>NaN</td>\n",
              "      <td>La taille de l’écran</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Un homme</td>\n",
              "      <td>Itinéo</td>\n",
              "      <td>Utilisateur (sans pouvoir installer des applic...</td>\n",
              "      <td>Word;Excel;Outlook;Diplomatie;Diplonet;Viséo;F...</td>\n",
              "      <td>Toujours accessibles et rapides à trouver</td>\n",
              "      <td>En général</td>\n",
              "      <td>Individuellement avec plusieurs personnes</td>\n",
              "      <td>Messagerie</td>\n",
              "      <td>14/03/2022 12:43:00</td>\n",
              "      <td>Terminé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ministère de l'Europe et des Affaires Etrangères</td>\n",
              "      <td>Très mal</td>\n",
              "      <td>Majoritairement nomade (déplacements fréquents...</td>\n",
              "      <td>Régulièrement (1 à 3 fois par mois)</td>\n",
              "      <td>Ordinateur fixe;Ordinateur portable;Smartphone</td>\n",
              "      <td>Moins bien</td>\n",
              "      <td>Oui, parce qu'il est plus performant</td>\n",
              "      <td>L’absence de bugs (dysfonctionnement du logici...</td>\n",
              "      <td>La possibilité de travailler simultanément sur...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Une femme</td>\n",
              "      <td>Itinéo;Smarteo</td>\n",
              "      <td>Utilisateur (sans pouvoir installer des applic...</td>\n",
              "      <td>Excel;Word;Diplonet;Portail Elise;Powerpoint;V...</td>\n",
              "      <td>Toujours accessibles et rapides à trouver</td>\n",
              "      <td>En général</td>\n",
              "      <td>Au sein de votre équipe</td>\n",
              "      <td>Discussion instantanée</td>\n",
              "      <td>14/03/2022 14:11:52</td>\n",
              "      <td>Terminé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ministère de l'Europe et des Affaires Etrangères</td>\n",
              "      <td>Plutôt bien</td>\n",
              "      <td>Majoritairement sédentaire (lieu de travail fi...</td>\n",
              "      <td>Jamais</td>\n",
              "      <td>Ordinateur fixe</td>\n",
              "      <td>Moins bien</td>\n",
              "      <td>Non, je ne le souhaite pas</td>\n",
              "      <td>L’espace de stockage</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Un homme</td>\n",
              "      <td>Aucun</td>\n",
              "      <td>Utilisateur (sans pouvoir installer des applic...</td>\n",
              "      <td>RMV-France Visas;Portail Elise;Sagha;Colimatic...</td>\n",
              "      <td>Toujours accessibles mais difficiles à trouver</td>\n",
              "      <td>En général</td>\n",
              "      <td>Avec d'autres équipes</td>\n",
              "      <td>Messagerie</td>\n",
              "      <td>14/03/2022 14:12:45</td>\n",
              "      <td>Terminé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ministère de l'Europe et des Affaires Etrangères</td>\n",
              "      <td>Très bien</td>\n",
              "      <td>Majoritairement sédentaire (lieu de travail fi...</td>\n",
              "      <td>Rarement (de 1 à 11 jours par an)</td>\n",
              "      <td>Ordinateur portable;Smartphone</td>\n",
              "      <td>Ni mieux, ni moins bien</td>\n",
              "      <td>Non, je ne le souhaite pas</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Les ports disponibles (USB, HDMI, VGA...)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Une femme</td>\n",
              "      <td>Itinéo;Smarteo</td>\n",
              "      <td>Utilisateur (sans pouvoir installer des applic...</td>\n",
              "      <td>Word;Diplonet;Excel;Portail Elise;Powerpoint;V...</td>\n",
              "      <td>Toujours accessibles mais difficiles à trouver</td>\n",
              "      <td>En général</td>\n",
              "      <td>Avec d'autres équipes</td>\n",
              "      <td>Messagerie;Discussion instantanée;Echanges ora...</td>\n",
              "      <td>14/03/2022 14:13:51</td>\n",
              "      <td>Terminé</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ministère de l'Europe et des Affaires Etrangères</td>\n",
              "      <td>Plutôt bien</td>\n",
              "      <td>Majoritairement nomade (déplacements fréquents...</td>\n",
              "      <td>Très régulièrement (1 jour par semaine ou plus)</td>\n",
              "      <td>Ordinateur portable;Smartphone</td>\n",
              "      <td>Ni mieux, ni moins bien</td>\n",
              "      <td>Non, je ne le souhaite pas</td>\n",
              "      <td>NaN</td>\n",
              "      <td>L’encombrement (taille, poids de l’équipement)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>Un homme</td>\n",
              "      <td>Itinéo;Smarteo</td>\n",
              "      <td>Utilisateur (sans pouvoir installer des applic...</td>\n",
              "      <td>Word;Diplonet;Sagha;Excel;Portail Elise;Powerp...</td>\n",
              "      <td>Je dois les rechercher</td>\n",
              "      <td>Non</td>\n",
              "      <td>Avec d'autres équipes</td>\n",
              "      <td>Echanges oraux (présentiel ou visioconférence)...</td>\n",
              "      <td>14/03/2022 14:14:35</td>\n",
              "      <td>Terminé</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 59 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a214db85-baa2-412a-af4a-159281a32ab7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a214db85-baa2-412a-af4a-159281a32ab7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a214db85-baa2-412a-af4a-159281a32ab7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kfwUMBEprEn",
        "outputId": "62a8f0fd-5573-4033-fde6-d68e009be688"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Ministere', 'Q1.Maitrise_ENT', 'Q2.Sedentaire_ou_nomade',\n",
              "       'Q3.Frequence_teletravail', 'Q4.Equipements_possedes',\n",
              "       'Q5.equipement_prive_vs_pro', 'Q6.Utilisation_equipement_prive',\n",
              "       'Q7.amelioration_Ordinateur_Fixe',\n",
              "       'Q8.amelioration_Ordinateur_Portable', 'Q9.amelioration_Tablette',\n",
              "       'Q10.amelioration_smartphone', 'Q11.Satisfaction_equipement',\n",
              "       'Q12.Qualification_equipement',\n",
              "       'Q13.Equipement_utile_et_ecoresponsable',\n",
              "       'Q14.Elements_ameliorer_reseau', 'Q15.Satisfaction_connectivite',\n",
              "       'Q16.Amelioration_outils_et_app', 'Web_conf_Etat', 'Webinaire',\n",
              "       'Audioconference_de_lEtat', 'Osmose', 'Resana', 'Tchap',\n",
              "       'France_Transfert', 'Maia', 'RenoiRH', 'Chorus_DT', 'Vaas', 'Mentor',\n",
              "       'Chorus', 'Q18.condition_securite', 'Q19.Satisfaction_outils_et_app',\n",
              "       'Q20.souhait_formation', 'Q21.domaine_formation',\n",
              "       'Q22.Formation_outils', 'Q23.Formation_outils_Autre',\n",
              "       'Q24.format_formation', 'Q25.services_accompagnement',\n",
              "       'Q26.services_accompagnement_Autre',\n",
              "       'Q27.satisfaction_service_d_assistance', 'Q28.satisfaction_ENT',\n",
              "       'Q29.travail_a_distance', 'Q30.Remarques_ENT', 'Q31.Tranche_age',\n",
              "       'Q32.contact_public', 'Q33.Fonction_encadrement', 'Q34.categorie',\n",
              "       'Q35.Statut', 'QS0_MEAE', 'QS1_MEAE_genre',\n",
              "       'QS2_MEAE_outils_de_travail_a_distance',\n",
              "       'QS3_MEAE_niveau_acces_equipements', 'QS4_MEAE_applications',\n",
              "       'QS5_MEAE_informations', 'QS6_MEAE_informations_bis',\n",
              "       'QS7_MEAE_interactions', 'QS8_MEAE_activites', 'DATE_ENREG',\n",
              "       'PROGRESSION'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Q11.Satisfaction_equipement'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLJCWFIBp6ZN",
        "outputId": "dda92026-cfeb-4227-c638-0c845f51a621"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Plutôt satisfait', 'Plutôt pas satisfait', 'Très satisfait',\n",
              "       'Pas du tout satisfait', nan], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['Q31.Tranche_age', 'Q34.categorie', 'Q11.Satisfaction_equipement', 'QS2_MEAE_outils_de_travail_a_distance']]\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "1w7bcfKZpoFZ"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Q11.Satisfaction_equipement']=df['Q11.Satisfaction_equipement'].replace('Plutôt satisfait', 1)\n",
        "df['Q11.Satisfaction_equipement']=df['Q11.Satisfaction_equipement'].replace('Très satisfait', 1)\n",
        "df['Q11.Satisfaction_equipement']=df['Q11.Satisfaction_equipement'].replace('Plutôt pas satisfait', 0)\n",
        "df['Q11.Satisfaction_equipement']=df['Q11.Satisfaction_equipement'].replace('Pas du tout satisfait', 0)"
      ],
      "metadata": {
        "id": "-CTQxlY5pT63"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#histogramme\n",
        "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
        "https://stackoverflow.com/questions/62974490/how-do-i-add-percent-values-on-top-of-histogram-bar-in-matplotlib"
      ],
      "metadata": {
        "id": "nAHXiOZeq5eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%pylab inline\n",
        "#import pymysql\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.lines as mlines\n",
        "from numpy.core.umath_tests import inner1d\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import statsmodels.api as sm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance, to_graphviz\n",
        "#import tensorflow as tf\n",
        "#from keras.models import Sequential\n",
        "#from keras.layers import Dropout, Dense\n",
        "from sklearn import model_selection\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, roc_auc_score   \n",
        "#from minisom import MiniSom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsNHxAO4w7nu",
        "outputId": "a29ddcc3-dd16-4f9e-b78c-7864abb15a4f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['f']\n",
            "`%matplotlib` prevents importing * from pylab and numpy\n",
            "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "df['Smarteo']=df['QS2_MEAE_outils_de_travail_a_distance'].str.contains('Smarteo', regex=True)"
      ],
      "metadata": {
        "id": "iZNDg9YPq5h-"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Smarteo'] = df['Smarteo'].replace({True: 'Oui', False: 'Non'})"
      ],
      "metadata": {
        "id": "9eTltayKq5l4"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Q11.Satisfaction_equipement']\n",
        "X = df.drop(columns = ['Q11.Satisfaction_equipement','QS2_MEAE_outils_de_travail_a_distance'],axis=1)"
      ],
      "metadata": {
        "id": "ZJCw3Vzcq5qU"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "zOoujKR2osL3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install autokeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjHXMR770SnW",
        "outputId": "f21b9278-4731-46cf-c280-6fd113512d46"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: autokeras in /usr/local/lib/python3.7/dist-packages (1.0.19)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from autokeras) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.3.5)\n",
            "Requirement already satisfied: keras-tuner>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (1.1.2)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from autokeras) (2.8.2+zzzcolab20220527125636)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.23.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (1.21.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner>=1.1.0->autokeras) (5.5.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.8.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.17.3)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (14.0.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.26.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.46.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (4.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.0.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.8.0->autokeras) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner>=1.1.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (4.11.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner>=1.1.0->autokeras) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner>=1.1.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner>=1.1.0->autokeras) (3.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner>=1.1.0->autokeras) (0.2.5)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->autokeras) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->autokeras) (2022.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import autokeras as ak"
      ],
      "metadata": {
        "id": "wZHsN3Wh0y1r"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "n1maOcNrosL3",
        "outputId": "a58258ea-e25f-4f15-efba-6333a6075b71"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-86-f3ee8b19841d>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    epochs=\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "train_features = X_train\n",
        "train_label = y_train\n",
        "test_features = X_test\n",
        "test_label = y_test\n",
        "\n",
        "estimateur = ak.StructuredDataClassifier()\n",
        "\n",
        "epochs=\n",
        "estimateur.fit(x=train_features,\n",
        "y=train_label,\n",
        "validation_data=(test_features, test_label), epochs=epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjR1zAMdosL3"
      },
      "outputs": [],
      "source": [
        "tensorboard --logdir logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txJX6pJhosL3",
        "outputId": "ba5be999-2b56-44d8-b3fd-494b54ef2da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 3)]               0         \n",
            "                                                                 \n",
            " multi_category_encoding (Mu  (None, 3)                0         \n",
            " ltiCategoryEncoding)                                            \n",
            "                                                                 \n",
            " normalization (Normalizatio  (None, 3)                7         \n",
            " n)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                128       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32)               128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32)               128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            " classification_head_1 (Acti  (None, 1)                0         \n",
            " vation)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,480\n",
            "Trainable params: 1,345\n",
            "Non-trainable params: 135\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "best_model = estimateur.export_model()\n",
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSyQwu2vosL4"
      },
      "outputs": [],
      "source": [
        "test_features = test_features.astype('float')\n",
        "test_features.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "xF04gpi3osL4"
      },
      "outputs": [],
      "source": [
        "predicted_l = best_model.predict(X_train) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.assign(predictions_satisfaction = predicted_l)"
      ],
      "metadata": {
        "id": "_iWBFqpDuer6"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['predictions_satisfaction'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqYypKCvu59C",
        "outputId": "6694d5f2-756b-4ec2-fd3c-cb36af84ba7f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7490061521530151"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#classification des commentaires selon trois modalités (neutres, positifs et négatifs) dans un dataframe\n",
        "def f(df_polarity_desc1):\n",
        "    if df_polarity_desc1['sentiment'] > 0:\n",
        "        val = \"positive\"\n",
        "    elif df_polarity_desc1['sentiment'] < 0:\n",
        "        val = \"negative\"\n",
        "    else :\n",
        "        val = \"neutre\"\n",
        "    return val\n",
        "\n",
        "df_polarity_desc1.apply(f, axis=1)\n",
        "df_polarity_desc1['polarite']=df_polarity_desc1.apply(f, axis=1)"
      ],
      "metadata": {
        "id": "Hmrv5Jy0wpNw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "7523f641-d95d-42d0-bbe0-74ce773e56ca"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-d9fe4d66155b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdf_polarity_desc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdf_polarity_desc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'polarite'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_polarity_desc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_polarity_desc1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#classe = 0\n",
        "def f(X_train) :\n",
        "  if X_train['predictions_satisfaction'] > 0.5 :\n",
        "    classe = 1\n",
        "  elif X_train['predictions_satisfaction'] <= 0.5 :\n",
        "    classe = 0\n",
        "  return classe\n",
        "\n",
        "X_train.apply(f, axis=1)\n",
        "\n",
        "X_train['classes']=X_train.apply(f, axis=1)"
      ],
      "metadata": {
        "id": "h07yyQBY3IjB"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['classes'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnEx4tslx6YW",
        "outputId": "8051298e-6fa4-47d5-a6d3-fd5773a717ac"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['classes'].mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1aOUQbpv4z8",
        "outputId": "2c8126ab-df4e-41c2-c3e0-6ff7c5027b11"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train= X_train.drop('predictions_satisfaction', axis=1)"
      ],
      "metadata": {
        "id": "6RrTl_Fv2XZJ"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train= X_train.drop('predictions_satisfaction', axis=1)\n",
        "X_train= X_train.drop('classes', axis=1)"
      ],
      "metadata": {
        "id": "OZGl8vyp2MRH"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfr = []\n",
        "x = range(50)\n",
        "\n",
        "for n in x : \n",
        "  res = 'X' + str(n)\n",
        "  dfr.append(res)"
      ],
      "metadata": {
        "id": "vALq4bia1QPf"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy"
      ],
      "metadata": {
        "id": "aA_gae9C2Ovc"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = []\n",
        "for data in dfr :\n",
        "  data = X.copy()\n",
        "  data['Itinéo'] = np.ramdom.permutation(data['Itinéo'].values)\n",
        "  predicted_y = best_model.predict(data)\n",
        "  data = data.assign(predictions_satisfaction=predicted_y)\n",
        "  result=data['predictions_satisfaction'].mean()\n",
        "  res.append(result)"
      ],
      "metadata": {
        "id": "HKEBod2E19f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "d71be1db-cda8-4988-8431-e659d8416f3e"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-1a2926bd224e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfr\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Itinéo'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mramdom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Itinéo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mpredicted_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_satisfaction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0;32m--> 314\u001b[0;31m                                  \"{!r}\".format(__name__, attr))\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'ramdom'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fsJ4eD_9yvml",
        "outputId": "beb7a908-5c4b-4210-8a4c-755521bc8a66"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Q31.Tranche_age Q34.categorie Smarteo  classes\n",
              "2089  Entre 25 et 34 ans             A     Non        1\n",
              "1975  Entre 35 et 49 ans             A     Oui        1\n",
              "1186  Entre 25 et 34 ans             C     Non        1\n",
              "1180  Entre 35 et 49 ans             C     Non        1\n",
              "883   Entre 50 et 64 ans             A     Oui        1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7cd89b70-df65-42d7-93e8-9f725024e9a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q31.Tranche_age</th>\n",
              "      <th>Q34.categorie</th>\n",
              "      <th>Smarteo</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2089</th>\n",
              "      <td>Entre 25 et 34 ans</td>\n",
              "      <td>A</td>\n",
              "      <td>Non</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1975</th>\n",
              "      <td>Entre 35 et 49 ans</td>\n",
              "      <td>A</td>\n",
              "      <td>Oui</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1186</th>\n",
              "      <td>Entre 25 et 34 ans</td>\n",
              "      <td>C</td>\n",
              "      <td>Non</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1180</th>\n",
              "      <td>Entre 35 et 49 ans</td>\n",
              "      <td>C</td>\n",
              "      <td>Non</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>Entre 50 et 64 ans</td>\n",
              "      <td>A</td>\n",
              "      <td>Oui</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7cd89b70-df65-42d7-93e8-9f725024e9a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7cd89b70-df65-42d7-93e8-9f725024e9a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7cd89b70-df65-42d7-93e8-9f725024e9a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Max = [0,0,0,0]\n",
        "\n",
        "for data in dfr  :\n",
        "    data = X_train.copy()\n",
        "    #print(predicted_y)\n",
        "    data['Smarteo'] = np.random.permutation(data['Smarteo'].values)\n",
        "    #data['Smarteo'] = np.random.permutation(data['Smarteo'].values)\n",
        "    predicted_y = best_model.predict(data)\n",
        "    data = data.assign(predictions_satisfaction = predicted_y)\n",
        "   \n",
        "    # on fait la moyenne par catégorie\n",
        "    dfgpby = data.groupby(['Q34.categorie'], as_index=False).mean()\n",
        "    dfgpby.head()\n",
        "    # on sauvegarde les noms des catégories et les moyennes associées\n",
        "    categories = dfgpby['Q34.categorie'].values\n",
        "    moyennes = dfgpby['predictions_satisfaction'].values\n",
        "    print(categories)\n",
        "    print(moyennes)\n",
        "   \n",
        "    pas_max = False\n",
        "    # Boucle sur chaque catégorie\n",
        "    for ind,val in enumerate(categories):\n",
        "        # Si pour au moins une des catégories on n'est pas le Max,\n",
        "        # alors on met passe le booléen à vrai pour l'indiquer\n",
        "        if moyennes[ind] <= Max[ind]:\n",
        "            pas_max = True\n",
        "           \n",
        "    # Si on a trouvé qu'on est max pour toutes les catégories,\n",
        "    # alors on boucle et on sauvegarde\n",
        "    if pas_max == False:\n",
        "        for ind,val in enumerate(categories):\n",
        "            Max[ind] = moyennes[ind]\n",
        "        col = data['Smarteo'].values\n",
        "        pred = data['predictions_satisfaction'].values\n",
        "        data = data.assign(Itinéo = col)\n",
        "        data = data.assign(predictions_satisfaction = pred)\n",
        "        datadg = data.groupby(['Q34.categorie'])[['predictions_satisfaction', 'Smarteo']].agg(['mean', 'sum', 'count'])"
      ],
      "metadata": {
        "id": "4FHqcG8G19kE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4878046-5c04-4f0a-8ae4-e1baab3b66b0"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091485 0.70634   0.7067832 0.7998672]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70914495 0.7062559  0.7067991  0.80001086]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091739  0.7066101  0.70684034 0.7999066 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70914495 0.706323   0.7067547  0.79996717]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70911044 0.7062868  0.7067868  0.7999914 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7092057 0.7065765 0.7067258 0.800049 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7092501  0.7064524  0.706869   0.80006814]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70910406 0.70621765 0.7068951  0.7998336 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70917034 0.7063001  0.70679116 0.79990935]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7092628  0.7063656  0.70681304 0.79997826]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7092184  0.70620316 0.70671815 0.8001296 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7092148  0.7063689  0.7067495  0.79991966]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091739 0.7062723 0.7067658 0.7999464]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091894  0.7065962  0.70676285 0.7998369 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091132  0.70623285 0.70677817 0.79999155]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091485 0.7065441 0.7067081 0.8000215]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091005  0.7062058  0.70681816 0.79990065]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.709243   0.7062262  0.70675087 0.7999916 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091485  0.70641917 0.70679826 0.7998502 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091485  0.70646244 0.7067172  0.79997224]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091993  0.70620376 0.7066594  0.8001183 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091866  0.7063474  0.70676124 0.79996306]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70914215 0.70635134 0.7068058  0.79994184]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091259  0.70641917 0.706716   0.79994017]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70911956 0.70619667 0.7067907  0.79992586]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091922 0.7063935 0.7068329 0.8000242]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70917034 0.70624655 0.70682687 0.79996365]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091922  0.70631987 0.7068176  0.80004096]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091132  0.706307   0.70683414 0.79989064]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.709212  0.7060518 0.7068169 0.800027 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70914215 0.70628095 0.70677793 0.79999346]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7092311 0.7066199 0.7068555 0.7999699]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70914215 0.7062018  0.70687413 0.79992956]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70918024 0.7063539  0.7068071  0.8000709 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70911676 0.7063307  0.70669657 0.80013716]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70915765 0.7061181  0.70677036 0.79989564]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7092247  0.70646775 0.706696   0.8001191 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70913506 0.7065541  0.70680016 0.7999889 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70915484 0.7062275  0.7067063  0.80003804]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70913506 0.7061065  0.7067146  0.8000312 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091767 0.7065397 0.7068071 0.799992 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091767  0.7065279  0.70674604 0.8000699 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70915484 0.7061868  0.70678985 0.8000158 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70913225 0.7063182  0.7067627  0.8000369 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7092021  0.7066192  0.70680064 0.7998547 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70918304 0.706762   0.70681584 0.7999219 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091132  0.7063553  0.70671654 0.79993325]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70917034 0.7063322  0.7068056  0.8000334 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.70914215 0.7061889  0.70680934 0.7998327 ]\n",
            "['A' 'A+' 'B' 'C']\n",
            "[0.7091866  0.7065496  0.7067979  0.79996854]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " X_train.groupby(['Q34.categorie'])[['predictions_satisfaction', 'Smarteo']].agg(['mean', 'sum', 'count'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "xn7K6taW2pQY",
        "outputId": "56e9af5f-6100-4c1e-fada-f08f804235e2"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-cdc9307a6ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Q34.categorie'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predictions_satisfaction'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Smarteo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1536\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1537\u001b[0m             )\n\u001b[0;32m-> 1538\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                 \u001b[0mbad_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Columns not found: {str(bad_keys)[1:-1]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Columns not found: 'predictions_satisfaction'\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datadg"
      ],
      "metadata": {
        "id": "vt5V7ZTf19oQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8ecd25c0-e13d-4e78-f677-b6cbb085538d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              predictions_satisfaction                  \n",
              "                                  mean         sum count\n",
              "Q34.categorie                                           \n",
              "A                             0.709231  349.650909   493\n",
              "A+                            0.706620   97.513542   138\n",
              "B                             0.706855  228.314316   323\n",
              "C                             0.799970  599.977417   750"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d768d4ad-d16a-4ca1-8b36-ad9a614ff18d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"3\" halign=\"left\">predictions_satisfaction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>sum</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q34.categorie</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>A</th>\n",
              "      <td>0.709231</td>\n",
              "      <td>349.650909</td>\n",
              "      <td>493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>A+</th>\n",
              "      <td>0.706620</td>\n",
              "      <td>97.513542</td>\n",
              "      <td>138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>0.706855</td>\n",
              "      <td>228.314316</td>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C</th>\n",
              "      <td>0.799970</td>\n",
              "      <td>599.977417</td>\n",
              "      <td>750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d768d4ad-d16a-4ca1-8b36-ad9a614ff18d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d768d4ad-d16a-4ca1-8b36-ad9a614ff18d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d768d4ad-d16a-4ca1-8b36-ad9a614ff18d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IEtxgYLz19sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jcKMnsv4osL4"
      },
      "outputs": [],
      "source": [
        "print(predicted_l[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-x3Vi25DosL4"
      },
      "outputs": [],
      "source": [
        " tf.keras.utils.plot_model(best_model, show_shapes=True, expand_nested=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxkTipiNosL4"
      },
      "outputs": [],
      "source": [
        "pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CC_sVUKxosL4"
      },
      "outputs": [],
      "source": [
        "train_features.dtypes\n",
        "train_features.astype('float')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg9bqr4MosL4"
      },
      "outputs": [],
      "source": [
        "test_features.astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nE-zsozosL4"
      },
      "outputs": [],
      "source": [
        "# use Kernel SHAP to explain test set predictions\n",
        "import shap\n",
        "explainer = shap.KernelExplainer(best_model.predict, train_features)\n",
        "shap_values = explainer.shap_values(test_features, nsamples=100)\n",
        "shap.force_plot(explainer.expected_value[0], shap_values[0][0,:], test_features.iloc[0,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7mX7sinosL4"
      },
      "outputs": [],
      "source": [
        "# plot the SHAP values for the Setosa output of all instances\n",
        "shap.force_plot(explainer.expected_value[0], shap_values[0], X_test, link=\"logit\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMUBPHlnosL5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_eA5LT7osL5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ersx_KyXosL5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjiXy--UosL5"
      },
      "outputs": [],
      "source": [
        "import shap  \n",
        "test = test_features.iloc[:100].flatten()\n",
        "explainer = shap.DeepExplainer(best_model, test)\n",
        "\n",
        "# calculate shap values. This is what we will plot.\n",
        "#shap_values = explainer.shap_values(test_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzqfYplMosL5"
      },
      "outputs": [],
      "source": [
        "import lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QS2MJRkHosL5"
      },
      "outputs": [],
      "source": [
        "columns = ['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwyVbzYnosL5"
      },
      "outputs": [],
      "source": [
        "# changed x to x_train\n",
        "import lime.lime_tabular\n",
        "explainer = lime.lime_tabular.LimeTabularExplainer(train_features, class_names=[0, 1], mode='classification')\n",
        "# added top_labels=1\n",
        "exp = explainer.explain_instance(test_features[2], best_model.predict, num_features=6, top_labels=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymrnsemiosL5"
      },
      "outputs": [],
      "source": [
        "def f(test_features):\n",
        "    return best_model.predict([test_features[:,i] for i in range(test_features.shape[1])]).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22XzIKqOosL5"
      },
      "outputs": [],
      "source": [
        "explainer = shap.KernelExplainer(f, test_features.iloc[:50,:])\n",
        "shap_values = explainer.shap_values(test_features.iloc[299,:], nsamples=500)\n",
        "shap.force_plot(explainer.expected_value, shap_values, X_display.iloc[299,:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNZRNVpPosL6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoaMXrisosL6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyyDUDzhosL6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amPth0V_osL6"
      },
      "outputs": [],
      "source": [
        "best_model.predict(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M14sThrrosL6"
      },
      "outputs": [],
      "source": [
        "background = train_features.iloc[10, :]\n",
        "background.dtypes\n",
        "background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTim9_51osL6"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "# load your data here, e.g. X and y\n",
        "# create and fit your model here\n",
        "\n",
        "# load JS visualization code to notebook\n",
        "shap.initjs()\n",
        "\n",
        "# explain the model's predictions using SHAP\n",
        "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
        "#background = X[np.random.choice(X.shape[0],100)]\n",
        "background = train_features.iloc[10, :]\n",
        "explainer = shap.DeepExplainer(best_model,background)\n",
        "shap_values = explainer.shap_values(test_features)\n",
        "\n",
        "# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\n",
        "shap.force_plot(explainer.expected_value, shap_values[0,:], X.iloc[0,:])\n",
        "\n",
        "shap.summary_plot(shap_values, X, plot_type=\"bar\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HOikfeaosL6"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# we use the first 100 training examples as our background dataset to integrate over\n",
        "explainer = shap.DeepExplainer(best_model, X_train[:100])\n",
        "\n",
        "# explain the first 10 predictions\n",
        "# explaining each prediction requires 2 * background dataset size runs\n",
        "shap_values = explainer.shap_values(X_test[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDsOA0xposL6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctxzJYdfosL6"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rFDSmBIosL6"
      },
      "outputs": [],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4kIhtClosL7"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow==2.3.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2S3W46TosL7"
      },
      "outputs": [],
      "source": [
        "train_features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viBxe41OosL7"
      },
      "outputs": [],
      "source": [
        "train_features = train_features.drop(columns = ['Lname', 'Name', 'Sex', 'Ticket', 'Embarked', 'Cabin'],axis=1)\n",
        "test_features = test_features.drop(columns = ['Lname', 'Name', 'Sex', 'Ticket', 'Embarked', 'Cabin'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31VNA6ucosL7"
      },
      "outputs": [],
      "source": [
        "pip install lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDSacZPuosL7"
      },
      "outputs": [],
      "source": [
        "#train_features = train_features.as_matrix() \n",
        "feature_names = train_features.feature_names\n",
        "train_pandas_df = train_features[feature_names].as_data_frame() \n",
        "\n",
        "#test_features = test_feature.as_matrix() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4yOjOFcosL7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOxrjzZYosL7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGd8LKdXosL7"
      },
      "outputs": [],
      "source": [
        "train_features.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4Hu3LIYosL7",
        "outputId": "d471c001-62fa-4c24-84da-42a895bfe20d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId    float64\n",
              "Pclass         float64\n",
              "Age            float64\n",
              "SibSp          float64\n",
              "Parch          float64\n",
              "Fare           float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features = train_features.astype('float')\n",
        "train_features.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxTr_Y1QosL8",
        "outputId": "1bcc63ab-4d42-498c-bc48-028c3d9b4f07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId    float64\n",
              "Pclass         float64\n",
              "Age            float64\n",
              "SibSp          float64\n",
              "Parch          float64\n",
              "Fare           float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_features = train_features.astype('float')\n",
        "train_features.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2kxquo2osL8",
        "outputId": "8b49b93a-7b4e-40dd-ed27-2639cd178bf3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PassengerId    float64\n",
              "Pclass         float64\n",
              "Age            float64\n",
              "SibSp          float64\n",
              "Parch          float64\n",
              "Fare           float64\n",
              "dtype: object"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_features = test_features.astype('float')\n",
        "test_features.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY9D1UZ7osL8",
        "outputId": "f834079e-035c-46d7-d705-afb35e6913d4"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['Lname' 'Name' 'Sex' 'Ticket' 'Embarked' 'Cabin'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-125-547175493964>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Lname'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ticket'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Embarked'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Cabin'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4165\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4166\u001b[0m         \"\"\"\n\u001b[1;32m-> 4167\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   4168\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4169\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3885\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3886\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3887\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3888\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3919\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3920\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3921\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3922\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5283\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5284\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5285\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: \"['Lname' 'Name' 'Sex' 'Ticket' 'Embarked' 'Cabin'] not found in axis\""
          ]
        }
      ],
      "source": [
        "test_features = test_features.drop(columns = ['Lname', 'Name', 'Sex', 'Ticket', 'Embarked', 'Cabin'],axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Vx7a1VFosL8",
        "outputId": "d42fe01c-555d-4933-a134-ed2990ab1cfa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'as_list'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-126-eef7c8443916>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# explain predictions of the model on three images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# ...or pass tensors directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFDeep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_phase_flags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pytorch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPyTorchDeep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m    156\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                     \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheNameYouWant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         training=training_mode):\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    268\u001b[0m                              \u001b[1;34m' is incompatible with layer '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m                              \u001b[1;34m': expected shape='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m                              ', found shape=' + display_shape(x.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36mdisplay_shape\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'as_list'"
          ]
        }
      ],
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "# select a set of background examples to take an expectation over\n",
        "#background = y_train[np.random.choice(y_train.shape[0], 100)]\n",
        "\n",
        "# explain predictions of the model on three images\n",
        "e = shap.DeepExplainer(best_model, train_features)\n",
        "# ...or pass tensors directly\n",
        "# e = shap.DeepExplainer((model.layers[0].input, model.layers[-1].output), background)\n",
        "shap_values = e.shap_values(test_features[1:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9AWp8eEosL8",
        "outputId": "d89ee797-fe3a-4c57-efd5-d8a3c9c28764"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-1.10.1-cp38-cp38-win_amd64.whl (226.6 MB)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\valha\\anaconda3\\lib\\site-packages (from torch) (3.7.4.3)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.10.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAgWXbnqosL9",
        "outputId": "3afc7c1f-1fb1-43fe-eec9-377da6223875"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'torch.Size' object has no attribute 'as_list'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-131-9debc10185e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# It wants gradients enabled, and uses the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Get the shap values from my test data (this explainer likes tensors)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTFDeep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_phase_flags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'pytorch'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPyTorchDeep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m    156\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                     \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtheNameYouWant\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1011\u001b[0m         training=training_mode):\n\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m       \u001b[0minput_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0meager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mcall_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    268\u001b[0m                              \u001b[1;34m' is incompatible with layer '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlayer_name\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m                              \u001b[1;34m': expected shape='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m                              ', found shape=' + display_shape(x.shape))\n\u001b[0m\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36mdisplay_shape\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 274\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'torch.Size' object has no attribute 'as_list'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import shap\n",
        "import numpy\n",
        "import pandas\n",
        "\n",
        "# It wants gradients enabled, and uses the training set\n",
        "torch.set_grad_enabled(True)\n",
        "e = shap.DeepExplainer(best_model, Variable( torch.from_numpy( train_features.to_numpy(dtype=np.float32) ) ) )\n",
        "\n",
        "# Get the shap values from my test data (this explainer likes tensors)\n",
        "shap_values = e.shap_values( Variable( torch.from_numpy(test_features.to_numpy(dtype=np.float32)) ) )\n",
        "\n",
        "# Plots\n",
        "#shap.force_plot(explainer.expected_value, shap_values, feature_names)\n",
        "#shap.dependence_plot(\"b1_price_avg\", shap_values, data, feature_names)\n",
        "shap.summary_plot(shap_values, test_features.to_numpy(dtype=np.float32), feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F_Xbs76osL9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BON.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}